{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3fb12cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F \n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data._utils.collate import default_collate\n",
    "\n",
    "from typing import List, Tuple\n",
    "import random\n",
    "from uuid import uuid4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "import syft as sy\n",
    "\n",
    "from util import Client, Server\n",
    "\n",
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bac06ab",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2370f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, ids, data, labels, *args, **kwargs):\n",
    "        'Initialization'\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.ids = ids\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Load data and get label\n",
    "        uuid = self.ids[index]\n",
    "        if self.data is not None:\n",
    "            X = self.data[index]\n",
    "        else:\n",
    "            X = None\n",
    "        if self.labels is not None:\n",
    "            y = self.labels[index]\n",
    "        else:\n",
    "            y = None\n",
    "        return uuid, X, y\n",
    "    \n",
    "    def get_ids(self) -> List[str]:\n",
    "        \"\"\"Return a list of the ids of this dataset.\"\"\"\n",
    "        return [str(_) for _ in self.ids]\n",
    "    \n",
    "    def sort_by_ids(self):\n",
    "        \"\"\"Sort the dataset by IDs in ascending order\"\"\"\n",
    "        ids = self.get_ids()\n",
    "        sorted_idxs = np.argsort(ids)\n",
    "\n",
    "        if self.data is not None:\n",
    "            self.data = self.data[sorted_idxs] \n",
    "\n",
    "        if self.labels is not None:\n",
    "            self.labels = self.labels[sorted_idxs]\n",
    "\n",
    "        self.ids = self.ids[sorted_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ba1ff19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_dataset(\n",
    "    dataset: Dataset,\n",
    "    keep_order: bool = False,\n",
    ") -> Tuple[Dataset, Dataset]:\n",
    "    'Vertically partition a torch dataset in two'\n",
    "    partition1 = copy.deepcopy(dataset)\n",
    "    partition2 = copy.deepcopy(dataset)\n",
    "    \n",
    "    # p1 has all features, p2 has all labels\n",
    "    partition1.labels = None\n",
    "    partition2.data = None\n",
    "    \n",
    "    # disorder indexing\n",
    "    idxs1 = np.arange(len(partition1)) \n",
    "    idxs2 = np.arange(len(partition2))\n",
    "    \n",
    "    if not keep_order:\n",
    "        np.random.shuffle(idxs1)\n",
    "        np.random.shuffle(idxs2)\n",
    "        \n",
    "    partition1.data = partition1.data[idxs1]\n",
    "    partition1.ids = partition1.ids[idxs1]\n",
    "\n",
    "    partition2.labels = partition2.labels[idxs2]\n",
    "    partition2.ids = partition2.ids[idxs2]\n",
    "    \n",
    "    return partition1, partition2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9af42d",
   "metadata": {},
   "source": [
    "## Partitioned Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25fdba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerticalDataLoader:\n",
    "    def __init__(self, dataset, *args, **kwargs):\n",
    "        # Split datasets\n",
    "        self.partition1, self.partition2 = partition_dataset(dataset)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.partition1)\n",
    "    \n",
    "    def drop_non_intersection(self, intersection: List[int]):\n",
    "        \"\"\"Remove elements and ids in the datasets that are not in the intersection.\"\"\"\n",
    "        self.partition1.data = self.partition1.data[intersection]\n",
    "        self.partition1.ids = self.partition1.ids[intersection]\n",
    "\n",
    "        self.partition2.labels = self.partition2.labels[intersection]\n",
    "        self.partition2.ids = self.partition2.ids[intersection]\n",
    "        \n",
    "    def sort_by_ids(self) -> None:\n",
    "        \"\"\"Sort each dataset by ids\"\"\"\n",
    "        self.partition1.sort_by_ids()\n",
    "        self.partition2.sort_by_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c45d4a0",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "599134a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {'batch_size': 1,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 6}\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "# Dataset\n",
    "ids = np.array([uuid4() for i in range(10)])\n",
    "partition = torch.randn((10, 30))\n",
    "labels = torch.randint(0, 2, (10,))\n",
    "\n",
    "# Generator\n",
    "data = Dataset(ids, partition, labels)\n",
    "dataloader = VerticalDataLoader(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d89941",
   "metadata": {},
   "source": [
    "## Implement PSI and order the datasets accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2643a937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patitioned data is disordered\n",
      "Patitioned data is aligned\n"
     ]
    }
   ],
   "source": [
    "if dataloader.partition1.ids[:].all() != dataloader.partition2.ids[:].all():\n",
    "    print(\"Patitioned data is disordered\")\n",
    "    \n",
    "# Compute private set intersection\n",
    "client_items = dataloader.partition1.get_ids()\n",
    "server_items = dataloader.partition2.get_ids()\n",
    "\n",
    "client = Client(client_items)\n",
    "server = Server(server_items)\n",
    "\n",
    "setup, response = server.process_request(client.request, len(client_items))\n",
    "intersection = client.compute_intersection(setup, response)\n",
    "\n",
    "# Order data\n",
    "dataloader.drop_non_intersection(intersection)\n",
    "dataloader.sort_by_ids()\n",
    "\n",
    "if dataloader.partition1.ids[:].all() == dataloader.partition2.ids[:].all():\n",
    "    print(\"Patitioned data is aligned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4f27a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f93cb11b0b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Parser:\n",
    "    def __init__(self):\n",
    "        self.epochs = 100\n",
    "        self.lr = 0.01\n",
    "        self.seed = 0\n",
    "        self.input_size = 30 # 30 dimensions\n",
    "        self.hidden_sizes = [128, 640] # can be altered\n",
    "        self.output_size = 2 # 0 or 1\n",
    "    \n",
    "args = Parser()\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16b9ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net():\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def backward(self):\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def zero_grads(self):\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def step(self):\n",
    "        \n",
    "        return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a82e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create workers\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
